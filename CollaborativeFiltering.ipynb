{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Collaborative_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKt3zNDUGOmZ",
        "colab_type": "text"
      },
      "source": [
        "# RMSE and MAE using Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI0u6YD7Wswz",
        "colab_type": "code",
        "outputId": "2e17105c-9844-47d2-a1ad-39a0fbcab565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PovH-T67beBi",
        "colab_type": "text"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrQkJog7VvDJ",
        "colab_type": "code",
        "outputId": "36cbd1ba-ac23-4da5-f771-b2e15079aa98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pylab inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/YelpDataset')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A1iKt0tVvDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# citation: https://cambridgespark.com/content/tutorials/implementing-your-own-recommender-systems-in-Python/index.html\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import cross_validate as cv\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vobYXESlVvDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(ratings, similarity, type='user'):\n",
        "    if type == 'user':\n",
        "        mean_user_rating = ratings.mean(axis=1)\n",
        "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
        "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
        "    elif type == 'item':\n",
        "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
        "    return pred\n",
        "\n",
        "def rmse(prediction, ground_truth):\n",
        "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
        "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
        "\n",
        "def mae(prediction, ground_truth):\n",
        "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
        "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
        "    return mean_absolute_error(prediction, ground_truth)\n",
        "\n",
        "\n",
        "def collaborativeFiltering(reviews_source):\n",
        "    reviews = pd.read_csv(reviews_source)\n",
        "    reviews['text'] = reviews['text'].str[2:-2]\n",
        "\n",
        "    \n",
        "    print(\"The Dataset is Undersampled as it is a large Dataset to prevent runtime Crashing\")\n",
        "    \n",
        "    #Balancing Dataset by undersampling\n",
        "    review1 = reviews[reviews['stars'] == 1][0:2000]\n",
        "    review2 = reviews[reviews['stars'] == 2][0:2000]\n",
        "    review3 = reviews[reviews['stars'] == 3][0:2000]\n",
        "    review4 = reviews[reviews['stars'] == 4][0:2000]\n",
        "    review5 = reviews[reviews['stars'] == 5][0:2000]\n",
        "    frames = [review1, review2, review3,review4,review5]\n",
        "    reviews = pd.concat(frames)\n",
        "    \n",
        "    print(\"The Undersampling is completed\")\n",
        "    \n",
        "    # Converting Business ID and User ID for the matrix\n",
        "    reviews['user_id'] = pd.factorize(reviews.user_id)[0]\n",
        "    reviews['business_id'] = pd.factorize(reviews.business_id)[0]\n",
        "    \n",
        "    # Generating unique users and restaurants from review dataset\n",
        "    unique_users = reviews.user_id.unique().shape[0]\n",
        "    unique_restaurants = reviews.business_id.unique().shape[0]\n",
        "    \n",
        "    #splitting the dataset\n",
        "    train_data, test_data = train_test_split(reviews, test_size=0.20)\n",
        "\n",
        "    #Creating two User-Item matrix for training and testing\n",
        "    train_data_matrix = np.zeros((unique_users, unique_restaurants))\n",
        "    \n",
        "    print(\"User-Item matrix creation has started\")\n",
        "    \n",
        "    # Training user-item matrix\n",
        "    for line in train_data.itertuples():\n",
        "         train_data_matrix[line[3], line[2]] = line[5]\n",
        "            \n",
        "    # Testing user-item matrix\n",
        "    test_data_matrix = np.zeros((unique_users, unique_restaurants))\n",
        "    for line in test_data.itertuples():\n",
        "        test_data_matrix[line[3], line[2]] = line[5]\n",
        "    \n",
        "    print(\"User-Item matrix creation has been completed\")\n",
        "    \n",
        "    print(\"Similarity matrix creation has begun\")\n",
        "    \n",
        "   # User-User similarity is calculated using cosine similarity\n",
        "    user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
        "    # Item-Item similarity is calculated using cosine similarity\n",
        "    item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n",
        "    \n",
        "    print(\"Similarity matrix creation has been completed\")\n",
        "    \n",
        "    \n",
        "    print(\"Prediction matrix creation based on Item and User has been started\")\n",
        "    \n",
        "    item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
        "    user_prediction = predict(train_data_matrix, user_similarity, type='user')\n",
        "    \n",
        "    print(\"Prediticon matrix creation has been completed\")\n",
        "    \n",
        "    print('The Root Mean Square Error and Mean Absolute Error is being generated' + '\\n')\n",
        "    \n",
        "    if reviews_source == 'reviews_restaurants_text.csv':\n",
        "        rating_type = 'biased rating'\n",
        "    elif reviews_source == 'reviews_restaurants_text_unbiased_svm.csv':\n",
        "        rating_type = 'unbiased rating from Linear SVM'\n",
        "    else:\n",
        "        rating_type = 'unbiased rating from Naive Bayes'\n",
        "    print ('The Root mean Square Error for Item-based and User-based similarity with' + rating_type)\n",
        "    print ('The User-Based Collaborative Filtered Root Mean Square Error is: ' + str(rmse(user_prediction, test_data_matrix)))\n",
        "    print ('The Item-Based Collaborative Filtered Root Mean Square Error is:' + str(rmse(item_prediction, test_data_matrix)) + '\\n')\n",
        "\n",
        "    print ('The Root mean Square Error for Item-based and User-based similarity with' + rating_type)\n",
        "    print ('The User-Based Collaborative Filtered Root Mean Square Error is:' + str(rmse(user_prediction, train_data_matrix)))\n",
        "    print ('The Item-Based Collaborative Filtered Root Mean Square Error is:' + str(rmse(item_prediction, train_data_matrix)) + '\\n')\n",
        "    \n",
        "    print ('The Mean Absolute for Item-based and User-based similarity with' + rating_type)\n",
        "    print ('The User-Based Collaborative Filtered Mean Absolute Error is:' + str(mae(user_prediction, test_data_matrix)))\n",
        "    print ('The Item-Based Collaborative Filtered Root Mean Square Error is:' + str(mae(item_prediction, test_data_matrix)) + '\\n')\n",
        "\n",
        "    print ('The Mean Absolute for Item-based and User-based similarity with' + rating_type)\n",
        "    print ('The User-Based Collaborative Filtered Mean Absolute Error is:' + str(mae(user_prediction, train_data_matrix)))\n",
        "    print ('The Item-Based Collaborative Filtered Root Mean Square Error is:' + str(mae(item_prediction, train_data_matrix)) + '\\n')   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdl5jOb9VvDd",
        "colab_type": "text"
      },
      "source": [
        "## Filtering based on Biased Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNeYJ-NwVvDe",
        "colab_type": "code",
        "outputId": "457d8ef3-2619-48cc-cb51-25a6c7ffb543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "collaborativeFiltering('reviews_restaurants_text.csv')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Dataset is Undersampled as it is a large Dataset to prevent runtime Crashing\n",
            "The Undersampling is completed\n",
            "User-Item matrix creation has started\n",
            "User-Item matrix creation has been completed\n",
            "Similarity matrix creation has begun\n",
            "Similarity matrix creation has been completed\n",
            "Prediction matrix creation based on Item and User has been started\n",
            "Prediticon matrix creation has been completed\n",
            "The Root Mean Square Error and Mean Absolute Error is being generated\n",
            "\n",
            "The Root mean Square Error for Item-based and User-based similarity withbiased rating\n",
            "The User-Based Collaborative Filtered Root Mean Square Error is: 3.315758126267929\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:3.3174030361627893\n",
            "\n",
            "The Root mean Square Error for Item-based and User-based similarity withbiased rating\n",
            "The User-Based Collaborative Filtered Root Mean Square Error is:3.313777500890382\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:3.3151086767609956\n",
            "\n",
            "The Mean Absolute for Item-based and User-based similarity withbiased rating\n",
            "The User-Based Collaborative Filtered Mean Absolute Error is:2.9930308876284863\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:2.9946872334848678\n",
            "\n",
            "The Mean Absolute for Item-based and User-based similarity withbiased rating\n",
            "The User-Based Collaborative Filtered Mean Absolute Error is:2.9990796812582974\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:3.00012958884516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9LB1BQ5UVvDi",
        "colab_type": "text"
      },
      "source": [
        "## Filtering Based on UnBiased Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcRA0uSUVvDi",
        "colab_type": "code",
        "outputId": "5a0a8979-9beb-4de8-de05-09fde12a71af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "collaborativeFiltering('reviews_restaurants_text_unbiased_svm.csv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Dataset is Undersampled as it is a large Dataset to prevent runtime Crashing\n",
            "The Undersampling is completed\n",
            "User-Item matrix creation has started\n",
            "User-Item matrix creation has been completed\n",
            "Similarity matrix creation has begun\n",
            "Similarity matrix creation has been completed\n",
            "Prediction matrix creation based on Item and User has been started\n",
            "Prediticon matrix creation has been completed\n",
            "The Root Mean Square Error and Mean Absolute Error is being generated\n",
            "\n",
            "The Root mean Square Error for Item-based and User-based similarity withunbiased rating from Linear SVM\n",
            "The User-Based Collaborative Filtered Root Mean Square Error is: 3.309791216966111\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:3.311251452365215\n",
            "\n",
            "The Root mean Square Error for Item-based and User-based similarity withunbiased rating from Linear SVM\n",
            "The User-Based Collaborative Filtered Root Mean Square Error is:3.3153240448613337\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:3.3166378831126457\n",
            "\n",
            "The Mean Absolute for Item-based and User-based similarity withunbiased rating from Linear SVM\n",
            "The User-Based Collaborative Filtered Mean Absolute Error is:2.9966070626084558\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:2.9981431368887344\n",
            "\n",
            "The Mean Absolute for Item-based and User-based similarity withunbiased rating from Linear SVM\n",
            "The User-Based Collaborative Filtered Mean Absolute Error is:2.9982286184572513\n",
            "The Item-Based Collaborative Filtered Root Mean Square Error is:2.9992609180489476\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}